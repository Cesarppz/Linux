{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f249019-a3c9-42dd-92ae-28a6545c4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8eca43-6420-482d-b32d-3314606dc29b",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c822075b-b359-402a-ae57-ba6249ad71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse_incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59665690-4fb8-4be3-ae5d-620b58512bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_list = []\n",
    "with open('../data/UD_Spanish-AnCora/es_ancora-ud-dev.conllu','r',encoding='utf-8') as f:\n",
    "    for token_list in parse_incr(f):\n",
    "        word_list.append(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3160f37-795f-483c-afef-a4f816cfe8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'form': 'El',\n",
       " 'lemma': 'el',\n",
       " 'upos': 'DET',\n",
       " 'xpos': None,\n",
       " 'feats': {'Definite': 'Def',\n",
       "  'Gender': 'Masc',\n",
       "  'Number': 'Sing',\n",
       "  'PronType': 'Art'},\n",
       " 'head': 2,\n",
       " 'deprel': 'det',\n",
       " 'deps': None,\n",
       " 'misc': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd34a2f-7355-4944-b64b-dae8e7a6d462",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo - cálculo de probabilidades\n",
    "\n",
    "$$P(t_i|w_i, t_{i-1}) = \\frac{C(t_i, w_i, t_{i-1})}{C(w_i, t_{i-1})}$$\n",
    "* `Prob_dict` = $\\large C(t_i, w_i, t_{i-1})$\n",
    "* `Context_dict` = $\\large C(w_i, t_{i-1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a08c65a-aa69-454e-a75a-7337e7d0ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_dict(dict_t,tag):\n",
    "    if tag in dict_t.keys():\n",
    "        dict_t[tag] += 1\n",
    "    else:\n",
    "        dict_t[tag] = 1\n",
    "    return dict_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "07838908-4983-48aa-8b74-060442a5c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prob_dict = {}\n",
    "Context_dict = {}\n",
    "Unique_prob = {}\n",
    "\n",
    "with open('../data/UD_Spanish-AnCora/es_ancora-ud-train.conllu','r',encoding='utf-8') as f:\n",
    "    for token_list in parse_incr(f):\n",
    "        pre_tag = 'NONE'\n",
    "        for token in token_list:\n",
    "        # Prob_dict\n",
    "            tag = token['upos']+'|'+token['form'].lower()+','+ pre_tag\n",
    "            Prob_dict = counter_dict(Prob_dict,tag)\n",
    "\n",
    "        # Context Dict\n",
    "\n",
    "            tag_c = token['form'].lower()+','+ pre_tag\n",
    "            Context_dict = counter_dict(Context_dict,tag_c)\n",
    "\n",
    "        # Unique Dict\n",
    "\n",
    "    #         tag_u = token['upos']+'|'+token['form']+','+ pre_tag\n",
    "\n",
    "    #         Unique_prob[tag_u] = Prob_dict[tag]/Context_dict[tag_c]\n",
    "\n",
    "            pre_tag = token['upos']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d22b23b-b04c-4757-8a17-c29bf983e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Prob_dict.keys():\n",
    "    if len(key.split('|')) == 3:\n",
    "        Unique_prob[key] = Prob_dict[key]/Context_dict['|'+key.split('|')[-1]]\n",
    "    else:\n",
    "        Unique_prob[key] = Prob_dict[key]/Context_dict[key.split('|')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "93b67fad-0314-4990-9ff8-ec632b3ed9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidad inicial\n",
    "inicialTagProb = {}\n",
    "count = 0\n",
    "with open('../data/UD_Spanish-AnCora/es_ancora-ud-train.conllu','r',encoding='utf-8') as f:\n",
    "    for token_list in parse_incr(f):\n",
    "        count += 1\n",
    "        token = token_list[0]['upos']\n",
    "        if token in inicialTagProb.keys():\n",
    "            inicialTagProb[token] += 1\n",
    "        else: \n",
    "            inicialTagProb[token] = 1\n",
    "for key in inicialTagProb.keys():\n",
    "    inicialTagProb[key] /= count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6254168e-7798-4bf4-8059-8115c16e3b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PUNCT': 0,\n",
       " 'VERB': 1,\n",
       " 'ADV': 2,\n",
       " 'NOUN': 3,\n",
       " 'PART': 4,\n",
       " '_': 5,\n",
       " 'AUX': 6,\n",
       " 'PRON': 7,\n",
       " 'SYM': 8,\n",
       " 'INTJ': 9,\n",
       " 'DET': 10,\n",
       " 'ADP': 11,\n",
       " 'CCONJ': 12,\n",
       " 'NUM': 13,\n",
       " 'SCONJ': 14,\n",
       " 'ADJ': 15,\n",
       " 'X': 16,\n",
       " 'PROPN': 17}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StateSetDict = {}\n",
    "for idx, p in enumerate(set([w.split('|')[0] for w in Prob_dict])):\n",
    "    StateSetDict[p] = idx\n",
    "StateSetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef225f7f-132c-47d5-82b6-7b8c2aa73587",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DET': 0.34799021321216356,\n",
       " 'ADP': 0.14931842013282068,\n",
       " 'VERB': 0.04557846906675987,\n",
       " 'ADV': 0.07577770010485844,\n",
       " 'PROPN': 0.10506815798671792,\n",
       " 'PRON': 0.04173365955959455,\n",
       " 'ADJ': 0.010136315973435861,\n",
       " 'CCONJ': 0.036980076896190144,\n",
       " 'PART': 0.002446696959105208,\n",
       " 'PUNCT': 0.09143656064313177,\n",
       " 'NOUN': 0.025026214610276126,\n",
       " 'NUM': 0.0068507514854945824,\n",
       " '_': 0.009227542817196784,\n",
       " 'SCONJ': 0.027123383432366307,\n",
       " 'AUX': 0.022789234533379936,\n",
       " 'INTJ': 0.0020272631946871723,\n",
       " 'SYM': 0.0004893393918210416}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inicialTagProb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7aef9f-3680-498c-ab94-c2747877f779",
   "metadata": {},
   "source": [
    "# Entrenamiento "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8bd58-11df-425d-bdab-f59e2259d892",
   "metadata": {},
   "source": [
    "### Construcción del algoritmo de Viterbi\n",
    "\n",
    "Dada una secuencia de palabras $\\{p_1, p_2, \\dots, p_n \\}$, y un conjunto de categorias gramaticales dadas por la convención `upos`, se considera la matriz de probabilidades de Viterbi así:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c c}\n",
    "\\begin{array}{c c c c}\n",
    "\\text{ADJ} \\\\\n",
    "\\text{ADV}\\\\\n",
    "\\text{PRON} \\\\\n",
    "\\vdots \\\\\n",
    "{}\n",
    "\\end{array} \n",
    "&\n",
    "\\left[\n",
    "\\begin{array}{c c c c}\n",
    "\\nu_1(\\text{ADJ}) & \\nu_2(\\text{ADJ}) & \\dots  & \\nu_n(\\text{ADJ})\\\\\n",
    "\\nu_1(\\text{ADV}) & \\nu_2(\\text{ADV}) & \\dots  & \\nu_n(\\text{ADV})\\\\ \n",
    "\\nu_1(\\text{PRON}) & \\nu_2(\\text{PRON}) & \\dots  & \\nu_n(\\text{PRON})\\\\\n",
    "\\vdots & \\vdots & \\dots & \\vdots \\\\ \\hdashline\n",
    "p_1 & p_2 & \\dots & p_n \n",
    "\\end{array}\n",
    "\\right] \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Donde las probabilidades de Viterbi en la primera columna (para una categoria $i$) están dadas por: \n",
    "\n",
    "$$\n",
    "\\nu_1(i) = \\underbrace{\\rho_i^{(0)}}_{\\text{probabilidad inicial}} \\times P(i \\vert p_1, \\text{\"None\"})\n",
    "$$\n",
    "\n",
    "y para las siguientes columnas: \n",
    "\n",
    "$$\n",
    "\\nu_{t}(j) = \\max_i \\{ \\overbrace{\\nu_{t-1}(i)}^{\\text{estado anterior}} \\times P(j \\vert p_t, i) \\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9e315675-ca00-40ed-836d-9058f0effe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MEMM(sentence, inicialTagProb=inicialTagProb, StateSetDict=StateSetDict, Unique_prob=Unique_prob, Context_dict=Context_dict):\n",
    "    s = word_tokenize(sentence)\n",
    "    viterbi_matrix = np.zeros([18,len(s)])\n",
    "    prev_tag = 'NONE'\n",
    "    result_list = []\n",
    "    #Primera columna de la matriz\n",
    "    for key in StateSetDict.keys():\n",
    "        tag_row = StateSetDict[key]\n",
    "        word_tag =  key+'|'+s[0]+','+prev_tag\n",
    "        if word_tag in Unique_prob:\n",
    "            viterbi_matrix[tag_row,0] = inicialTagProb[key]*Unique_prob[word_tag]\n",
    "            \n",
    "    #Segunda Columna de la matriz\n",
    "    for col in range(1,len(s)):\n",
    "    #Recorro de la segunda columna en adelante\n",
    "        for key in StateSetDict.keys():\n",
    "            tag_row = StateSetDict[key]\n",
    "            for key_p in StateSetDict.keys():\n",
    "                word_tag = key+'|'+s[col]+','+ key_p\n",
    "                if word_tag in Unique_prob:\n",
    "                    possible_probs = []\n",
    "                    for p_key in StateSetDict.keys():\n",
    "                        prev_tag_row = StateSetDict[p_key]\n",
    "                        prev_word_tag = s[col-1]+','+p_key\n",
    "                        if prev_word_tag in Context_dict.keys():\n",
    "                            #print(prev_word_tag, prev_tag_row)\n",
    "                            if viterbi_matrix[prev_tag_row,col-1] > 0:\n",
    "                                viterbi_prob = viterbi_matrix[prev_tag_row,col-1] * Unique_prob[word_tag]\n",
    "                                possible_probs.append(viterbi_prob)\n",
    "        \n",
    "                    viterbi_matrix[tag_row,col] = max(possible_probs)\n",
    "                    #print(possible_probs)\n",
    "\n",
    "    # Retornar el resultado \n",
    "    for idx,col in enumerate(s):\n",
    "        resul_idx = np.argmax(viterbi_matrix[:,idx])\n",
    "        for key in StateSetDict.keys():\n",
    "            if StateSetDict[key] == resul_idx:\n",
    "                result_list.append((col,key))\n",
    "                \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7f8ac70b-67c6-4818-a134-bf5335f94770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', 'DET'), ('mundo', 'PROPN'), ('es', 'AUX'), ('pequeño', 'ADJ')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEMM('el mundo es pequeño')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
