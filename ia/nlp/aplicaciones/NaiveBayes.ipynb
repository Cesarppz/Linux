{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ff2a2ff-495f-4f95-9381-27504efb8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e4021-d144-4531-b4d0-bdd16dee7312",
   "metadata": {},
   "source": [
    "Leer el corpus de los archivos descagados, donde estan clasificados los correos spam y no-spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9233c0f-f6cb-49d3-ab54-10ef3d210a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd9dae59-07b3-4306-8759-7dc8bfce1a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cesar/Documents/master/ia/nlp/aplicaciones\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418fcf74-220e-4e30-963e-4c7195236d3c",
   "metadata": {},
   "source": [
    "Descomprimir el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba17430b-2601-46f5-9544-77a74664d968",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/enron5'\n",
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/enron2'\n",
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/corpus2'\n",
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/enron1'\n",
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/.ipynb_checkpoints'\n",
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/corpus1'\n",
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/enron3'\n",
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/corpus3'\n",
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/enron6'\n",
      "[Errno 21] Is a directory: '../data/datasets/email/plaintext/enron4'\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('../data/datasets/email/plaintext/'):\n",
    "    try:\n",
    "        with zipfile.ZipFile('../data/datasets/email/plaintext/'+file,'r') as zipobj:\n",
    "            zipobj.extractall('../data/datasets/email/plaintext/')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75557d7-b716-4d50-838e-9689e96151d5",
   "metadata": {},
   "source": [
    "Leer el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1714c0-7d2d-4344-a7f0-1d854831532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = [i for i in os.listdir('../data/datasets/email/plaintext/') if not i.endswith('.zip') and not i.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2024102f-6014-41f0-b0e4-2670a1054cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "clases = []\n",
    "# Spam\n",
    "for dir_p in files_path:\n",
    "    for file in os.listdir('../data/datasets/email/plaintext/'+dir_p+'/spam'):\n",
    "        if not file.startswith('.'):\n",
    "            with open('../data/datasets/email/plaintext/'+dir_p+'/spam/'+file, encoding='latin-1') as f:\n",
    "                data.append(f.read())\n",
    "                clases.append('spam')\n",
    "# No-Spam\n",
    "for dir_p in files_path:\n",
    "    for file in os.listdir('../data/datasets/email/plaintext/'+dir_p+'/ham'):\n",
    "        if not file.startswith('.'):\n",
    "            with open('../data/datasets/email/plaintext/'+dir_p+'/ham/'+file, encoding='latin-1') as f:\n",
    "                data.append(f.read())\n",
    "                clases.append('ham')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e5c94-2fb2-4c08-b1fa-78276d8818a8",
   "metadata": {},
   "source": [
    "# Creo el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9e6051a-2044-4449-89c1-e696c3ed9a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d1f95-8bdf-4577-8b45-d9b721db0b1b",
   "metadata": {},
   "source": [
    "Pruebo el tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5895c7f3-f157-4176-bc71-f18ba31db491",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Subject:',\n",
       " 'all',\n",
       " 'for',\n",
       " 'free',\n",
       " '!',\n",
       " 'check',\n",
       " 'out',\n",
       " 'these',\n",
       " '100',\n",
       " '%',\n",
       " 'free',\n",
       " 'adult',\n",
       " 'sites',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '\\n',\n",
       " '100',\n",
       " '%',\n",
       " 'free',\n",
       " 'porn',\n",
       " '!',\n",
       " '\\n',\n",
       " 'what',\n",
       " 'more',\n",
       " 'can',\n",
       " 'you',\n",
       " 'ask',\n",
       " 'for',\n",
       " '?',\n",
       " '\\n',\n",
       " 'click',\n",
       " 'here',\n",
       " '\\n',\n",
       " 'removal',\n",
       " 'instructions',\n",
       " ':',\n",
       " 'we',\n",
       " 'strive',\n",
       " 'to',\n",
       " 'never',\n",
       " 'send',\n",
       " 'unsolicited',\n",
       " 'mail',\n",
       " '.',\n",
       " '\\n',\n",
       " 'however',\n",
       " ',',\n",
       " 'if',\n",
       " 'you',\n",
       " \"'\",\n",
       " 'd',\n",
       " 'rather',\n",
       " 'not',\n",
       " 'receive',\n",
       " 'future',\n",
       " 'e',\n",
       " '-',\n",
       " 'mails',\n",
       " 'from',\n",
       " 'us',\n",
       " ',',\n",
       " '\\n',\n",
       " 'click',\n",
       " 'here',\n",
       " 'to',\n",
       " 'send',\n",
       " 'email',\n",
       " 'and',\n",
       " 'add',\n",
       " 'the',\n",
       " 'word',\n",
       " 'remove',\n",
       " 'in',\n",
       " 'the',\n",
       " 'subject',\n",
       " 'line',\n",
       " '.',\n",
       " '\\n',\n",
       " 'please',\n",
       " 'allow',\n",
       " '48',\n",
       " 'hours',\n",
       " 'for',\n",
       " 'processing',\n",
       " '.',\n",
       " '\\n',\n",
       " '[',\n",
       " 'j',\n",
       " '7',\n",
       " 'bjk',\n",
       " '9',\n",
       " '^',\n",
       " '\"',\n",
       " ':',\n",
       " '}',\n",
       " 'h',\n",
       " '&',\n",
       " '*',\n",
       " 'tgobk',\n",
       " '5',\n",
       " 'nkiys',\n",
       " '5',\n",
       " ']']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.text for t in tokenizer(data[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe839daa-9aa6-44bc-8c12-c5665fd8214d",
   "metadata": {},
   "source": [
    "### Clase principal para el algoritmo\n",
    "\n",
    "Recuerda que la clase más probable viene dada por (en espacio de cómputo logarítmico): \n",
    "\n",
    "\n",
    "$$\\hat{c} = {\\arg \\max}_{(c)}\\log{P(c)}\n",
    " +\\sum_{i=1}^n\n",
    "\\log{ P(f_i \\vert c)}\n",
    "$$\n",
    "\n",
    "Donde, para evitar casos atípicos, usaremos el suavizado de Laplace así:\n",
    "\n",
    "$$\n",
    "P(f_i \\vert c) = \\frac{C(f_i, c)+1}{C(c) + \\vert V \\vert}\n",
    "$$\n",
    "\n",
    "siendo $\\vert V \\vert$ la longitud del vocabulario de nuestro conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2d8fd5a-d4d3-48b8-8871-c0fdbeea4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    nlp = English()\n",
    "    tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "    def tokenize(self,data):\n",
    "        return [t.text.lower() for t in tokenizer(data)]\n",
    "    \n",
    "    def words_counts(self,words):\n",
    "        wordsCounts = {}\n",
    "        for word in words:\n",
    "            if word in wordsCounts.keys():\n",
    "                wordsCounts[word] += 1\n",
    "            else :\n",
    "                wordsCounts[word] = 1\n",
    "        return wordsCounts\n",
    "    \n",
    "    def fit(self, data, clases):\n",
    "        n = len(data)\n",
    "        self.unique_clases = set(clases)\n",
    "        self.vocab = set()\n",
    "        self.classCount = {} # C(c)\n",
    "        self.log_classPriorProb = {} # log(P(c))\n",
    "        self.wordCoditionalCounts = {} # C(w|c)\n",
    "        \n",
    "        #Conteo de las clases\n",
    "        self.classCount = self.words_counts(clases)\n",
    "            \n",
    "        #Calculo de la probabilidad c\n",
    "        for c in self.classCount.keys():\n",
    "            #La probabilidad de la clase\n",
    "            self.log_classPriorProb[c] = math.log(self.classCount[c]/n)\n",
    "            #Probabilidades condicionales de las palabras por cada clase\n",
    "            self.wordCoditionalCounts[c] = {}\n",
    "        #C(w|c)\n",
    "        for text, c in zip(data,clases):\n",
    "            counts = self.words_counts(self.tokenize(text))\n",
    "            \n",
    "            for word, count in counts.items():\n",
    "                # add las palabras al vocabulario\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab.add(word)\n",
    "                # add las palabras a el conteo condicional\n",
    "                if word not in self.wordCoditionalCounts[c]:\n",
    "                    self.wordCoditionalCounts[c][word] = 0.0\n",
    "                self.wordCoditionalCounts[c][word] += count\n",
    "    \n",
    "    def predict(self, data):\n",
    "        results = []\n",
    "        for text in data:\n",
    "            words = set(self.tokenize(text))\n",
    "            scoreProb = {}\n",
    "            for word in words:\n",
    "                if word not in self.vocab: continue\n",
    "                # Suavizado de laplace\n",
    "                for c in self.unique_clases:\n",
    "                    log_wordClassProb = math.log(\n",
    "                        (self.wordCoditionalCounts[c].get(word,0.0)+1) / (self.classCount[c]+len(self.vocab))  )\n",
    "                    scoreProb[c] = scoreProb.get(c,self.log_classPriorProb[c]) + log_wordClassProb\n",
    "            # Tomar la maxima probabilidad\n",
    "            arg_maxprob = np.argmax(np.array(list(scoreProb.values())))\n",
    "            results.append(list(scoreProb.keys())[arg_maxprob])\n",
    "        return results\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcacdbe8-5267-47c7-87f8-814ca1daab86",
   "metadata": {},
   "source": [
    "# Probar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24825824-2676-4b8f-966e-5526dba2bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, clases_train, clases_test = train_test_split(data,clases, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c408456-3b51-49cc-9043-5373c4323bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier()\n",
    "classifier.fit(data_train, clases_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa189ca8-8175-421e-8c39-b340e6127ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = classifier.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf205889-92d7-438d-9499-cade02ca9b3c",
   "metadata": {},
   "source": [
    "# Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fcbb931-ffd1-46db-ac8e-3ac3e2e74790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990612204134625"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predict,clases_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ad7115c-fc1c-4f18-82c9-d386ae346181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9912873 , 0.99004058])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(predict,clases_test, average=None, zero_division=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e044348-32d7-4821-9068-b9b893c83fac",
   "metadata": {},
   "source": [
    "De todos los ham que logré predecir el 99.12% es verdadero, de igual forma con el spam, de todos los spam que logré predecir el 99.04% fue verdadero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "208bb1d9-2e6a-417e-b1ec-6f86c6bbe3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98827362, 0.99260355])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(predict,clases_test, average=None, zero_division=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf3003-9ba5-4dce-a246-42885ccba13d",
   "metadata": {},
   "source": [
    "Por otro lado en el Recall, de todos los ham del dataset logré capturar el 98.82%, y de todos los spam en el dataset se logró capturar el 99.26%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "192ba24e-b43d-44aa-92ac-99281bde5707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4591"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases_test.count('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4bafa422-c368-4fa2-8f22-334c7792c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(clases_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d67b2dd-7577-4c9e-ba46-9ef7c338e720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham', 'spam']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0f7e3311-1cc0-4047-ab09-6449616bf6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(predict,clases_test, labels=['spam','ham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0a0ab00-fd7f-4612-8e98-16fb0cb7e308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5368,   40],\n",
       "       [  54, 4551]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a0d13295-c94a-48e4-a025-0f68096dad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(matrix, index = ['spam','ham'], columns = ['spam','ham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4832b0b0-17d1-4d38-beef-13dcbe44b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>5368</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>54</td>\n",
       "      <td>4551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam   ham\n",
       "spam  5368    40\n",
       "ham     54  4551"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12a39e-3275-4000-8c3c-472244a5353a",
   "metadata": {},
   "source": [
    "$$\\Large Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "* Cuántos de los correos clasificados como spam, realmente lo son ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "efab3e15-642e-42a9-9947-93bd2ea0454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992603550295858"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5368/(5368+40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802da3f-5969-4d6b-8288-1801557fb37e",
   "metadata": {},
   "source": [
    "$$\\Large Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "* Cuántos correos Spam lograron identificarse ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ce514d82-ee95-4ece-884e-56235c7cfda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900405754334194"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5368/(5368+54)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
