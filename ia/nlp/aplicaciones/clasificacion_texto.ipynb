{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c73d1b05-3f26-4ae7-8167-ea67c4afcab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random \n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e0a3dd-6641-437a-b669-c10cdb8b6e4b",
   "metadata": {},
   "source": [
    "# Clasificacion de palabras(Nombres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d46421-069e-4da9-a666-e798503761dd",
   "metadata": {},
   "source": [
    "## Attribute extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2681635a-30eb-4b8b-af79-079bdbdf1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d1a0a-44a0-4878-838f-dde9ac9b19d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4cea2d7a-a1e8-40bc-9b3d-fe0e20594935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute(word):\n",
    "    attr = {}\n",
    "    attr['last_word'] = word[-1].lower()\n",
    "    attr['lats_3_words'] = word[-4:].lower()\n",
    "    for letra in string.ascii_lowercase:\n",
    "        attr[f'{letra} in'] = np.where((letra in word),1,0).tolist()\n",
    "    return attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4753f612-3fd9-4458-a00c-cf04a738b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset = [(name,'M') for name in names.words('male.txt')] + [(name,'F') for name in names.words('female.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "63be4c0a-9e39-46f7-ad6e-efe79cc5dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bb785b0f-8eab-490b-8e18-e2e8d5382a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wittie', 'M'),\n",
       " ('Flossy', 'F'),\n",
       " ('Stanton', 'M'),\n",
       " ('Clarie', 'F'),\n",
       " ('Eldon', 'M'),\n",
       " ('Emmy', 'M'),\n",
       " ('Wynne', 'F'),\n",
       " ('Norah', 'F'),\n",
       " ('Gian', 'M'),\n",
       " ('Dionysus', 'M')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4c4e1804-a2a8-437d-b315-94b47a1c629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fset = [(attribute(name),g) for (name,g) in tagset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2999ab37-9db4-43b5-9b9d-b14fb75c5dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fset[:6355]\n",
    "test = fset[6355:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d1e7c-17fc-4153-815a-5d3c15b80c3f",
   "metadata": {},
   "source": [
    "## Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ba32c75b-c60e-47e1-af67-e31bc76f691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b41fab-3e44-4fee-afc2-328372c5553a",
   "metadata": {},
   "source": [
    "## Testing the algorith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2083ed5e-f7c6-45a1-81a1-f546d99e2d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(attribute('Jose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b67ef88e-81c1-40f1-b875-084077859152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7816236626809314"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d003cb6-dc93-4b15-bde9-e64cc866b507",
   "metadata": {},
   "source": [
    "# Clasificacion de documentos (Spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5cd54d8a-41ec-4684-b37d-2d10dccf63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "#import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5b20ef99-fdc9-4aa5-89e6-e80acdca44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/datasets/email/csv/spam-apache.csv', names=['clase','contenido'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1c0af41a-7989-41ec-8794-5b0d9a36c86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clase</th>\n",
       "      <th>contenido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt; Russell Turpin:\\n&gt; &gt; That depends on how the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>Help wanted.  We are a 14 year old fortune 500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>Request A Free No Obligation Consultation!\\nAc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Is there a way to look for a particular file o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt; From: Paul Linehan [mailto:plinehan@yahoo.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-1</td>\n",
       "      <td>REQUEST FOR URGENT BUSINESS ASSISTANCE\\n------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt; From: fork-admin@xent.com [mailto:fork-admin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-1</td>\n",
       "      <td>Email marketing works!  There's no way around ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-1</td>\n",
       "      <td>Email marketing works!  There's no way around ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clase                                          contenido\n",
       "0       -1  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...\n",
       "1        1  > Russell Turpin:\\n> > That depends on how the...\n",
       "2       -1  Help wanted.  We are a 14 year old fortune 500...\n",
       "3       -1  Request A Free No Obligation Consultation!\\nAc...\n",
       "4        1  Is there a way to look for a particular file o...\n",
       "..     ...                                                ...\n",
       "245      1  > From: Paul Linehan [mailto:plinehan@yahoo.co...\n",
       "246     -1  REQUEST FOR URGENT BUSINESS ASSISTANCE\\n------...\n",
       "247      1  > From: fork-admin@xent.com [mailto:fork-admin...\n",
       "248     -1  Email marketing works!  There's no way around ...\n",
       "249     -1  Email marketing works!  There's no way around ...\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f4c69-a9f6-4dc6-8747-9af68c946457",
   "metadata": {},
   "source": [
    "## Attribute extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8832fe15-c1e6-4fea-8d93-3c79afa626bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['contenido'].apply(lambda x : word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f1fe9-dcd6-4697-96a7-4e6bcd944774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "88b58fea-0d08-4d25-8590-b48a24d85b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "alll_words = nltk.FreqDist([w for token in df['tokens'] for w in token if w not in stopwords.words('english')])\n",
    "most_common = alll_words.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8c807d9b-0e94-4426-a281-7acfe5a3b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_attribute(document):\n",
    "    attr = {}\n",
    "    document_vocabulary = set(document)\n",
    "    for word , _ in most_common:\n",
    "        attr[f'Have {word}'] = np.where(word in document_vocabulary, 1, 0).tolist()\n",
    "    return attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e9b5df1f-c2d3-41c5-8632-50f3309ee01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicar los atributos y dividir la data en entrenamineto y test\n",
    "fset = [(document_attribute(w),v) for (w,v) in zip(df['tokens'],df['clase'])]\n",
    "n = int(len(df['tokens'])*80/100)\n",
    "train , test = fset[:n],fset[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c298e-e600-417f-8d0c-f2782903a439",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d2fe787a-584a-43c7-86d3-99c06962af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d35de817-b647-4211-aca9-7b5e74da3251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier,test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
