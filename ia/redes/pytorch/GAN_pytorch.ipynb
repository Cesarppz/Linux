{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E-F2y1jsc8SU"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpsqHB0av3vA"
   },
   "source": [
    "# Inportar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7E5BS7hPtJi4"
   },
   "outputs": [],
   "source": [
    "#cd 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6-xEUq1FpZ10"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/aitorzip/PyTorch-CycleGAN.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ie1qpYkqtfPP"
   },
   "outputs": [],
   "source": [
    "#cd './PyTorch-CycleGAN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bq2lPluRuKGt"
   },
   "outputs": [],
   "source": [
    "#%%sh \n",
    "#sh ./download_dataset summer2winter_yosemite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4Mo80HwZutZr"
   },
   "outputs": [],
   "source": [
    "#!mv datasets/summer2winter_yosemite /content/drive/MyDrive/Colab\\ Notebooks/IA/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffc0Pjs8nuB2"
   },
   "source": [
    "# Crear  la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnkDhcel6k3s"
   },
   "source": [
    "## Red Residual\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dqViEq7tvBuW"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self,in_features):\n",
    "    super(ResidualBlock,self).__init__()\n",
    "  \n",
    "    conv_block = [\n",
    "                nn.ReflectionPad2d(1), #Mejor padding #Hacer padding es rellenar la red, El Reflection padding hace un mejor padding que un cero padding, porque conserva mas la distribucion de la imagen.\n",
    "                nn.Conv2d(in_features, in_features, 3),\n",
    "                nn.InstanceNorm2d(in_features), #Para las GAN es mejor instance norm porque batch norm no maneja bien el contraste, pero instance norm no es tan buen regulizador como batch norm\n",
    "                nn.ReLU(True),\n",
    "                nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(in_features,in_features,3),\n",
    "                nn.InstanceNorm2d(in_features)\n",
    "  ]\n",
    "\n",
    "    self.conv_block = nn.Sequential(*conv_block)\n",
    "  \n",
    "  def forward(self,x):\n",
    "    return self.conv_block(x) + x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUU37H98tsmg"
   },
   "source": [
    "## Red Generativa\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_ot6AeWGgqg9"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self,input_channels,out_channels,n_residual_blocks=9):\n",
    "    super(Generator,self).__init__()\n",
    "\n",
    "    model = [nn.ReflectionPad2d(3),\n",
    "             nn.Conv2d(input_channels,64, 7), # ((I - 7 + 6)/1 )+ 1 = I El size de la imagen no se ve alterado\n",
    "             nn.InstanceNorm2d(64),\n",
    "             nn.ReLU(True)\n",
    "    ]\n",
    "\n",
    "    in_features = 64\n",
    "    out_features = in_features * 2\n",
    "\n",
    "    #Encoding (Compresion)\n",
    "\n",
    "    for _ in range(2):\n",
    "      model += [\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), # I/2\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(True)\n",
    "      ]\n",
    "      in_features = out_features\n",
    "      out_features = in_features * 2\n",
    "\n",
    "    # Transformaciones residuales \n",
    "    for _ in range(n_residual_blocks):\n",
    "      model += [ResidualBlock(in_features)]\n",
    "\n",
    "    # Decoding (Aumentar)\n",
    "    out_features = in_features // 2\n",
    "    for _ in range(2):\n",
    "      model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1), # 2*I  #Capas de deconvolucion\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "      ] \n",
    "\n",
    "      in_features = out_features\n",
    "      out_features = in_features //2\n",
    "    \n",
    "    #Salida\n",
    "    model += [ nn.ReflectionPad2d(3),\n",
    "              nn.Conv2d(64, out_channels, 7), #I\n",
    "              nn.Tanh()\n",
    "              ]\n",
    "\n",
    "    self.model = nn.Sequential(*model)\n",
    "  \n",
    "  def forward(self,x):\n",
    "    return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFrG14YRtwGm"
   },
   "source": [
    "## Red Discriminativa\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BhEq2OTztzKl"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  \" PatchGAN : Discrimina estilo o textura\"\n",
    "  def __init__(self,input_channels):\n",
    "    super(Discriminator,self).__init__()\n",
    "\n",
    "    model = [nn.Conv2d(input_channels, 64, 4, stride=2, padding=1), #I/2\n",
    "             nn.LeakyReLU(0.2, inplace=True),\n",
    "             ]\n",
    "\n",
    "    model += [nn.Conv2d(64, 128, 4, stride=2, padding=1), #I/2\n",
    "              nn.InstanceNorm2d(128),\n",
    "             nn.LeakyReLU(0.2, inplace=True),\n",
    "             ]\n",
    "    model += [nn.Conv2d(128, 256, 4, stride=2, padding=1), #I/2\n",
    "              nn.InstanceNorm2d(256),\n",
    "             nn.LeakyReLU(0.2, inplace=True),\n",
    "             ]\n",
    "    model += [nn.Conv2d(256, 512, 4, padding=1), #I-1\n",
    "              nn.InstanceNorm2d(512),\n",
    "             nn.LeakyReLU(0.2, inplace=True),\n",
    "             ]\n",
    "\n",
    "    #Flatten \n",
    "    model += [nn.Conv2d(512,1, 4, padding=1)] #I-1\n",
    "\n",
    "    self.model = nn.Sequential(*model)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.model(x)\n",
    "    return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1) #-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWQ2EDHk0h-Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-8YVpqV0RyU"
   },
   "source": [
    "# Preparar el entrenamiento\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mn7Z2ac30fNf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('data/')\n",
    "\n",
    "import os\n",
    "import glob #Manejo de files\n",
    "import random \n",
    "import itertools #Concatenaciones entre lista y iteradores\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import ReplayBuffer # Una forma de guardar las imagenes fake que va creando la red generativa y poder agregarla a la loss\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "from utils import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fF0x1GA_0Xn9"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "  def __init__(self, base_dir, transform = None , split='train'):\n",
    "    self.transform = transforms.Compose(transform)\n",
    "    self.file_A = sorted(glob.glob(os.path.join(base_dir, '{}/A/*.*'.format(split))))\n",
    "    self.file_B = sorted(glob.glob(os.path.join(base_dir, '{}/B/*.*'.format(split))))\n",
    "\n",
    "  def __len__(self):\n",
    "    return max(len(self.file_A), len(self.file_B))\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    Image_A = self.transform(Image.open(self.file_A[idx]))\n",
    "    Image_B = self.transform(Image.open(self.file_B[random.randint(0,len(self.file_B) - 1)]))\n",
    "    return  {\n",
    "        'A':Image_A,\n",
    "        'B':Image_B\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7WJ2Dnf34v4B"
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "n_epoch = 200\n",
    "batch_size = 2\n",
    "lr = 0.0002\n",
    "size = 256\n",
    "input_channels = 3\n",
    "output_channels = 3\n",
    "decay_epoch = 100\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "n_cpu = 2\n",
    "\n",
    "base_dir = 'data/summer2winter_yosemite'\n",
    "\n",
    "device = torch.device('cuda' if cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zdwNVNrvCdN9"
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "  if isinstance(m,nn.Conv2d) :\n",
    "    torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
    "  elif isinstance(m,nn.BatchNorm2d) :\n",
    "    torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
    "    torch.nn.init.constant(m.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L1Sw7eu2O5F3"
   },
   "outputs": [],
   "source": [
    "class LambdaLR():\n",
    "  def __init__(self,n_epoch, offset, decay_start_epoch):\n",
    "    assert((n_epoch - decay_start_epoch) > 0)\n",
    "    self.n_epoch = n_epoch\n",
    "    self.decay_start_epoch = decay_start_epoch\n",
    "    self.offset = offset\n",
    "\n",
    "  def step(self, epoch):\n",
    "    return 1 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epoch - self.decay_start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqt_oLeKFUGr",
    "outputId": "c970b2d6-6d5f-4f9f-a313-d4e55b002ef0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-98174b4ec082>:3: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n"
     ]
    }
   ],
   "source": [
    "netG_A2B = Generator(input_channels, output_channels)\n",
    "netG_B2A = Generator(input_channels, output_channels)\n",
    "netD_A   = Discriminator(input_channels)\n",
    "netD_B   = Discriminator(input_channels)\n",
    "\n",
    "#Inicializar pesos\n",
    "netG_A2B.apply(weights_init_normal)\n",
    "netG_B2A.apply(weights_init_normal)\n",
    "netD_A.apply(weights_init_normal)\n",
    "netD_B.apply(weights_init_normal)\n",
    "\n",
    "if cuda:\n",
    "  netG_A2B.to(device)\n",
    "  netG_B2A.to(device)\n",
    "  netD_A.to(device)\n",
    "  netD_B.to(device)\n",
    "\n",
    "#Perdida\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "#Optimizadores\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(),netG_B2A.parameters()), lr = lr, betas=(0.5,0.999))\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=lr, betas=(0.5,0.999))\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=lr, betas=(0.5,0.999))\n",
    "\n",
    "#Schedulers (Actualizar el lr de forma dinamica durante el entrenamiento)\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epoch,epoch,decay_epoch).step)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epoch,epoch,decay_epoch).step)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epoch,epoch,decay_epoch).step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhNl3csFuwvL",
    "outputId": "247d1af7-d062-41a5-9d80-9d2f7ecbfedc"
   },
   "outputs": [],
   "source": [
    "# inputs y Targets \n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor #Otra manera de llevar los tensores a gpu\n",
    "target_real = Tensor(batch_size).fill_(1.0)\n",
    "target_fake = Tensor(batch_size).fill_(0.0) \n",
    "\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "#Data Loader\n",
    "\n",
    "transform = [#transforms.Resize((100,100)),\n",
    "             transforms.Resize(int(size*1.12), Image.BICUBIC),\n",
    "             transforms.RandomCrop(size),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "             ]\n",
    "\n",
    "dataloader = DataLoader(ImageDataset(base_dir, transform), \n",
    "                        batch_size=batch_size, shuffle=True, \n",
    "                        num_workers=n_cpu, drop_last=True)  #Drop_last evitar que el dataloader se quede sin imagenes y de un error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v523C06jyCpq"
   },
   "source": [
    "## Funciones de Perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ietcSwnLyBel"
   },
   "outputs": [],
   "source": [
    "def Gen_GAN_loss(G, D, real, loss, target_real):\n",
    "  fake = G(real)\n",
    "  pred_fake = D(fake)\n",
    "  L = loss(pred_fake,target_real)\n",
    "  return L, fake\n",
    "\n",
    "def Dis_GAN_loss(D2, fake2, real2, fake_2_buffer, loss, target_real, target_fake):\n",
    "  pred_real = D2(real2)\n",
    "  loss_D2_real = loss(pred_real, target_real)\n",
    "\n",
    "  fake2 = fake_2_buffer.push_and_pop(fake2)\n",
    "  pred_fake = D2(fake2.detach())\n",
    "  loss_D2_fake = loss(pred_fake, target_fake)\n",
    "  loss_D2 = (loss_D2_real + loss_D2_fake) * 0.5\n",
    "  return loss_D2\n",
    "\n",
    "def cycle_loss(G1, G2, real, loss):\n",
    "  recovered = G2(G1(real))\n",
    "  L = loss(recovered, real)\n",
    "  return L\n",
    "\n",
    "def identity_loss(G, real, loss):\n",
    "  same = G(real)\n",
    "  L = loss(same,real)\n",
    "  return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KagY4ZzoZf2"
   },
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QW6lyuOyHcn9"
   },
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "logger = Logger(n_epoch, len(dataloader))\n",
    "liveloss = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0wbbGmGvPNf",
    "outputId": "6bbfc6a3-0425-402a-df99-63269afd3da6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/200 [0003/0615] -- loss_G: 18.4073 | loss_G_identity: 1.1292 | loss_G_cycle: 1.1687 | loss_G_GAN: 1.0740 | loss_D: 0.7979 -- ETA: 59 days, 23:35:11.271396"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-89f27bcd0f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss_cycle_BAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcycle_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG_B2A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetG_A2B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_cycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss_identity_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG_A2B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_identity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mloss_identity_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG_B2A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_identity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-0bf5e891473e>\u001b[0m in \u001b[0;36midentity_loss\u001b[0;34m(G, real, loss)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midentity_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0msame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-fd3d0cffa87a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-51da49432de0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ia/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch, n_epoch):\n",
    "  for i, batch in enumerate(dataloader):\n",
    "    real_A = batch['A'].to(device)\n",
    "    real_B = batch['B'].to(device)\n",
    "\n",
    "    #Generativas \n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    loss_GAN_A2B, fake_B = Gen_GAN_loss(netG_A2B, netD_B, real_A, criterion_GAN, target_real)\n",
    "    loss_GAN_B2A, fake_A = Gen_GAN_loss(netG_B2A, netD_A, real_B, criterion_GAN, target_real)\n",
    "\n",
    "    loss_cycle_ABA = cycle_loss(netG_A2B, netG_B2A, real_A, criterion_cycle)\n",
    "    loss_cycle_BAB = cycle_loss(netG_B2A, netG_A2B, real_B, criterion_cycle)\n",
    "\n",
    "    loss_identity_B = identity_loss(netG_A2B, real_B, criterion_identity)\n",
    "    loss_identity_A = identity_loss(netG_B2A, real_A, criterion_identity)\n",
    "\n",
    "    loss_G = (loss_GAN_A2B + loss_GAN_B2A) + 10.0*(loss_cycle_ABA+loss_cycle_BAB) + 5.0*(loss_identity_A + loss_identity_B)\n",
    "    loss_G.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    #Discriminativas\n",
    "    optimizer_D_A.zero_grad()\n",
    "    loss_D_A = Dis_GAN_loss(netD_A, fake_A, real_A, fake_A_buffer, criterion_GAN, target_real, target_fake)\n",
    "    loss_D_A.backward()\n",
    "    optimizer_D_A.step()\n",
    "\n",
    "    optimizer_D_B.zero_grad()\n",
    "    loss_D_B = Dis_GAN_loss(netD_B, fake_B, real_B, fake_B_buffer, criterion_GAN, target_real, target_fake)\n",
    "    loss_D_B.backward()\n",
    "    optimizer_D_B.step()\n",
    "\n",
    "\n",
    "    log_values = {\n",
    "        'loss_G':          loss_G,\n",
    "        'loss_G_identity':(loss_identity_A + loss_identity_B),\n",
    "        'loss_G_cycle':   (loss_cycle_ABA  + loss_cycle_BAB),\n",
    "        'loss_G_GAN' :    (loss_GAN_A2B    + loss_GAN_B2A),\n",
    "        'loss_D' :        (loss_D_A        + loss_D_B) \n",
    "    }\n",
    "\n",
    "    logger.log(log_values, images={'real_A':real_A, 'real_B':real_B, 'fake_A':fake_A, 'fake_B':fake_B})\n",
    "  \n",
    "  liveloss.update(log_values)\n",
    "  liveloss.draw()\n",
    "\n",
    "  lr_scheduler_G.step()\n",
    "  lr_scheduler_D_A.step()\n",
    "  lr_scheduler_D_B.step()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cpsqHB0av3vA"
   ],
   "name": "GAN_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:ia]",
   "language": "python",
   "name": "conda-env-ia-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
